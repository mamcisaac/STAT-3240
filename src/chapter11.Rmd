---
title: 'Chapter 11: Building the Regression Model III: Remedial Measures'
subtitle: 'STAT 3240'
author: "Michael McIsaac"
institute: "UPEI"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      slideNumberFormat: "%current%"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      navigation:
        scroll: false # disable slide transitions by scrolling
---

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
duo_accent(primary_color = "#006747", secondary_color = "#CFC493",   
	header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Roboto Mono"))
```		



```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE, fig.align="center", fig.height=5.5)
options(DT.options = list(scrollX = TRUE, pageLength=20, scrollY = 250))
options(digits = 4)
options(show.signif.stars=FALSE)

library(here)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(tidyverse)
library(ggplot2)
library(knitr)
library(mosaic)
library(DT)
library(car)
library(psych)
library(olsrr)

#params
spending_subset_all = read.csv(here("data", "spending_subset.csv"))

spending_subset=spending_subset_all[1:500,]

par(lwd=3,cex=1.5) 
cdi = as_tibble(read.delim(here("data", "CDI.txt"), sep=" ", header=FALSE)[,-c(1:2)] %>% mutate(V18 = recode_factor(V18, "NE", "NC", "S", "W")))
names(cdi) = c("county", "state", "land_area", "population", "pop_18_to_34", "pop_65", "number_physicians", "number_hospital_beds", "total_serious_crimes", "high_school_grads", "bachelor_degrees", "poverty_rate", "unemployment_rate", "per_capita_income", "total_personal_income", "region")

insurance <- read.delim(here("data", "CH10TA01.txt"), sep=" ", header=FALSE)
names(insurance) <- c("X1", "X2", "Y")


tab_model <- function(...,  show.ci=.95){sjPlot::tab_model(...,  show.ci=show.ci, show.se=TRUE, collapse.ci=TRUE, show.stat=TRUE)}
```



### 11.1: Remedial Measures for Unequal Error Variances: Weighted Least Squares
Suppose $Y_i = \beta_0 + \beta_1 X_{i1} + \cdots + \beta_{p-1} X_{i, p-1} + \varepsilon_i; \qquad \qquad \varepsilon_i \sim N(0, \sigma_i^2)$
so
$$\sigma^2\{\varepsilon\} = \left [ \begin{array}{cccc} \sigma_1^2 & 0 & \cdots & 0 \\  0 & \sigma_2^2 & \ddots  & \vdots \\  \vdots & \ddots & \ddots  & 0 \\  0 & \cdots & 0 &  \sigma_n^2 \\ \end{array} \right]$$
--

Then instead of finding parameter estimates that minimize the least squares criterion
$\sum_{i=1}^n(Y_i - (\beta_0 + \beta_1 X_{i1} + \cdots + \beta_{p-1} X_{i, p-1}))^2$  
we would be better off minimizing the *weighted least squares criterion*:
$$\sum_{i=1}^n w_i (Y_i - (\beta_0 + \beta_1 X_{i1} + \cdots + \beta_{p-1} X_{i, p-1}))^2, \qquad \text{ where } w_i = \frac{1}{\sigma_i^2}.$$
---

Consider 
$$\mathbb{W} = \left [ \begin{array}{cccc} w_1 & 0 & \cdots & 0 \\  0 & w_2 & \ddots  & \vdots \\  \vdots & \ddots & \ddots  & 0 \\  0 & \cdots & 0 &  w_n \\ \end{array} \right]$$
where, again, $w_i = \frac{1}{\sigma_i^2}$ would account for the unequal variances.

The weighted least squares estimators are 

$$\mathbb{b_w} = (\mathbb{X'WX})^{-1} \mathbb{X'W Y}$$
with variance-covariance matrix 
$$\mathbb{\sigma^2\{b_{w}\}} = (\mathbb{X'WX})^{-1}$$
--

We can also think about this as the OLS estimator in the scaled model
$$(\mathbb{W}^{	1/2} \mathbb{Y}) = (\mathbb{W}^{1/2} \mathbb{X}) \mathbb{\beta} + \mathbb{W}^{1/2} \mathbb{\varepsilon}$$

---

Of course, we won't know $\sigma_i^2 \ (i=1, \ldots, n)$ in practice, so we will need to estimate these in order to estimate the $w_i = 1/\sigma_i^2$. 

In some experimental settings, we may have sufficient replicates to estimate all of the $\sigma_i$ directly. 

More generally, we try to get a sense of how  $\sigma^2$ changes as $X_j$ or $\hat Y$ changes (just like we do when we attempt to identify non-constant variance). 

---

Weighted least squares estimation process:

1. Fit the regression model by unweighted least squares and analyze the residuals.

2. Estimate the variance function or the standard deviation function by regressing either the squared residuals or the absolute residuals on the appropriate predictor(s).

3. Use the fitted values from the estimated variance or standard deviation function to obtain the weights $w_i$.

4. Estimate the regression coefficients using these weights.

For *iteratively reweighted least squares*, we would iterate this process until convergence.

--

We need to do a little more work to correctly estimate standard errors of the parameter estimates. Bootstrapping can again help with this.

---

### 11.3: Remedial Measures for Influential Cases: Robust Regression

What to do when an influential case is found: 

* examine whether an outlying case is the result of a recording error.
  + if erroneous data can be corrected, this should be done. Otherwise, truly erroneous data should be discarded. 
  
* Many times, it is not possible to tell for certain whether the observations for an outlying case are erroneous.
  + Such cases should usually not be discarded.

* If an outlying influential case is not clearly erroneous, the next step should be to examine the adequacy of the model. 
  + Examination of these outlying cases may provide important clues as to how the model needs to be modified. 

---

* Discarding of outlying influential cases that are not clearly erroneous and that cannot be accounted for by model improvement should be done only rarely, such as when the model is not intended to cover the special circumstances related to the outlying case.

* An alternative to discarding outlying cases that is less severe is to dampen the influence of these cases. That is the purpose of **robust regression**.

--

One potential method of *robust regression* is to, again, employ *iteratively reweighted least squares* to minimize

$$\sum_{i=1}^n w_i (Y_i - (\beta_0 + \beta_1 X_{i1} + \cdots + \beta_{p-1} X_{i, p-1}))^2.$$

Here, instead of using weights that measure our uncertainty around a given point $(w_i = 1/\sigma_i^2)$, we use a weight that reduces the influence of outlying cases (so $w_i$ decreases as the size of the residual $e_i$ increases). 

---

This can be accomplished by the following steps:

1. Choose a weight function for weighting the cases.

2. Obtain starting weights for all cases.

3. Use the starting weights in weighted least squares and obtain the residuals from the fitted regression function.

4. Use the residuals in step 3 to obtain revised weights. 

5. Continue the iterations until convergence is obtained.

--

Robust regression, and weighted least squares, are often useful for confirming reasonableness of ordinary least squares results.
